import { NextRequest, NextResponse } from 'next/server';
import { callAI } from '@/lib/ai/ai-provider';

export const dynamic = 'force-dynamic';

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const message: string = body.message || '';
    const history = Array.isArray(body.history)
      ? body.history.map((h: any) => ({ role: h.sender === 'user' ? 'user' : 'assistant', content: String(h.content || '') }))
      : [];

    if (!message || typeof message !== 'string') {
      return NextResponse.json({ success: false, error: 'ë©”ì‹œì§€ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.' }, { status: 400 });
    }

    const system = `
ë‹¹ì‹ ì€ "ì´êµì¥ì˜AIìƒë‹´" ì‹œìŠ¤í…œì˜ Ollama phi3:mini ì „ìš© ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.

ğŸ¢ ì´êµì¥ì˜AIìƒë‹´ ì†Œê°œ:
- AI ì—­ëŸ‰ì§„ë‹¨ ë° ë§ì¶¤í˜• êµìœ¡ ì „ë¬¸ ê¸°ê´€
- ì´í›„ê²½ êµì¥ì´ ì´ë„ëŠ” AI/ë””ì§€í„¸ ì „í™˜ ì»¨ì„¤íŒ… íšŒì‚¬
- n8n, ChatGPT, Claude ë“± ì‹¤ë¬´ ì¤‘ì‹¬ êµìœ¡ ì œê³µ
- 100% ì˜¨ë””ë°”ì´ìŠ¤ Ollama phi3:mini AIë¡œ ì™„ì „ ë¬´ë£Œ ìƒë‹´

ğŸ’¬ ë‹µë³€ ì›ì¹™:
- ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- AICAMP ì„œë¹„ìŠ¤ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
- ê°„ê²°í•˜ë©´ì„œë„ ì¶©ë¶„í•œ ì •ë³´ ì œê³µ

ğŸ¯ ì£¼ìš” ì„œë¹„ìŠ¤:
- AI ì—­ëŸ‰ì§„ë‹¨ (45ê°œ í–‰ë™ì§€í‘œ)
- ë§ì¶¤í˜• AI êµìœ¡ê³¼ì •
- n8n ì—…ë¬´ ìë™í™” ì»¨ì„¤íŒ…
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ êµìœ¡
`;

    // ë°°í¬ í™˜ê²½ì—ì„œ ë¡œì»¬ Ollama í˜¸ì¶œ ë¶ˆê°€ ìƒí™© ì‚¬ì „ ì²˜ë¦¬
    const ollamaUrl = process.env.OLLAMA_API_URL || 'http://localhost:11434';
    const isServerless = !!process.env.VERCEL;

    if (isServerless && /localhost|127\.0\.0\.1/i.test(ollamaUrl)) {
      const fallback =
        'ì•ˆë…•í•˜ì„¸ìš”! í˜„ì¬ ë°°í¬ í™˜ê²½ì—ì„œëŠ” ë¡œì»¬ Ollama ì—”ì§„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì¦‰ì‹œ ë‹µë³€ì„ ì œê³µí•˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\n' +
        'ë¹ ë¥´ê²Œ ìƒë‹´ ì›í•˜ì‹œë©´ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.\n' +
        '1) ì „í™” 010-9251-9743\n' +
        '2) ì´ë©”ì¼ hongik423@gmail.com\n' +
        '3) ì¢Œì¸¡ ë²„íŠ¼ì—ì„œ AI ì—­ëŸ‰ì§„ë‹¨ì„ ë°”ë¡œ ì‹œì‘í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”.\n\n' +
        'ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤. ìš´ì˜ ì„œë²„ì— Ollamaê°€ ì—°ê²°ë˜ëŠ” ì¦‰ì‹œ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤.';

      const buttons = [
        { text: 'ğŸ¯ AI ì—­ëŸ‰ì§„ë‹¨', url: '/ai-diagnosis', style: 'primary', icon: 'Target' },
        { text: 'ğŸ“ ìƒë‹´ ì˜ˆì•½', url: '/consultation', style: 'secondary', icon: 'Phone' },
        { text: 'ğŸ“š êµìœ¡ê³¼ì • ë³´ê¸°', url: '/services/ai-curriculum', style: 'outline', icon: 'BookOpen' }
      ];

      return NextResponse.json({ success: true, response: fallback, buttons });
    }

    // GPT-OSS/phi3 ìµœì í™” ì„¤ì • (ì†ë„ ìš°ì„ )
    const responseText = await callAI({
      prompt: message,
      history,
      system,
      temperature: 0.6,
      maxTokens: 1536,
      timeoutMs: 120000
    });

    // ê¸°ë³¸ ì•¡ì…˜ ë²„íŠ¼
    const buttons = [
      { text: 'ğŸ¯ AI ì—­ëŸ‰ì§„ë‹¨', url: '/ai-diagnosis', style: 'primary', icon: 'Target' },
      { text: 'ğŸ“ ìƒë‹´ ì˜ˆì•½', url: '/consultation', style: 'secondary', icon: 'Phone' },
      { text: 'ğŸ“š êµìœ¡ê³¼ì • ë³´ê¸°', url: '/services/ai-curriculum', style: 'outline', icon: 'BookOpen' }
    ];

    return NextResponse.json({ 
      success: true, 
      response: responseText,
      buttons,
      metadata: {
        model: 'Ollama-GPT-OSS-20B-OnDevice',
        service: 'ì´êµì¥ì˜AIìƒë‹´-Ollamaì „ìš©',
        isOnDevice: true,
        apiCost: 0,
        externalAPI: false,
        aiProvider: 'ollama',
        localAI: true
      }
    });
  } catch (error: any) {
    // ë‚´ë¶€ ì˜¤ë¥˜ ë…¸ì¶œì„ í”¼í•˜ê³  ì¼ê´€ëœ ì•ˆë‚´ ì œê³µ
    const friendly =
      'ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n' +
      'ì§€ê¸ˆì€ ì¦‰ì‹œ ìƒë‹´ ì—°ê²°ì„ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤.\n' +
      'ì „í™” 010-9251-9743 / ì´ë©”ì¼ hongik423@gmail.com\n\n' +
      'ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì‹œë©´ ì •ìƒ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.';
    return NextResponse.json({ success: true, response: friendly }, { status: 200 });
  }
}


