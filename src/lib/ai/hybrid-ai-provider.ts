/**
 * í•˜ì´ë¸Œë¦¬ë“œ AI í”„ë¡œë°”ì´ë” - ì´êµì¥ì˜AIìƒë‹´ ì „ìš©
 * Vercel (ì„œë²„ë¦¬ìŠ¤) + ë¡œì»¬ Ollama (phi3:mini) í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ
 */

import { CallAIParams } from './hybrid-ai-provider.types';
import { HybridAIResponse, OllamaStatus, ServiceStatus } from './hybrid-ai-provider.types';
import { hostStatusMonitor } from '@/lib/monitoring/host-status-monitor';

export class HybridAIProvider {
  private static instance: HybridAIProvider;
  private ollamaStatus: OllamaStatus | null = null;
  private lastStatusCheck: number = 0;
  private readonly STATUS_CACHE_DURATION = 30000; // 30ì´ˆ ìºì‹œ

  private constructor() {}

  static getInstance(): HybridAIProvider {
    if (!HybridAIProvider.instance) {
      HybridAIProvider.instance = new HybridAIProvider();
    }
    return HybridAIProvider.instance;
  }

  /**
   * ë¡œì»¬ Ollama ì„œë²„ ìƒíƒœ í™•ì¸ (ìºì‹œëœ ê²°ê³¼ ì‚¬ìš©)
   */
  private async checkOllamaStatus(): Promise<OllamaStatus> {
    const now = Date.now();
    
    // ìºì‹œëœ ìƒíƒœê°€ ìˆê³  ì•„ì§ ìœ íš¨í•œ ê²½ìš°
    if (this.ollamaStatus && (now - this.lastStatusCheck) < this.STATUS_CACHE_DURATION) {
      return this.ollamaStatus;
    }

    try {
      console.log('ğŸ” ë¡œì»¬ Ollama ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘...');
      
      const baseUrl = process.env.NEXT_PUBLIC_VERCEL_URL || 'https://aicamp.club';
      const response = await fetch(`${baseUrl}/api/ollama/status`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        },
        signal: AbortSignal.timeout(5000)
      });

      if (!response.ok) {
        throw new Error(`ìƒíƒœ í™•ì¸ API ì˜¤ë¥˜: ${response.status}`);
      }

      const status = await response.json();
      this.ollamaStatus = status;
      this.lastStatusCheck = now;
      
      console.log(`ğŸ“Š Ollama ìƒíƒœ ì—…ë°ì´íŠ¸: ${status.isRunning ? 'ì‹¤í–‰ ì¤‘' : 'ì¤‘ì§€'}`);
      
      return status;
      
    } catch (error) {
      console.error('âŒ Ollama ìƒíƒœ í™•ì¸ ì‹¤íŒ¨:', error);
      
      const fallbackStatus: OllamaStatus = {
        isRunning: false,
        modelAvailable: false,
        modelName: 'phi3:mini',
        lastChecked: new Date().toISOString(),
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
      };
      
      this.ollamaStatus = fallbackStatus;
      this.lastStatusCheck = now;
      
      return fallbackStatus;
    }
  }

  /**
   * ë¡œì»¬ Ollama ì„œë²„ë¥¼ í†µí•œ AI í˜¸ì¶œ
   */
  private async callLocalOllama(params: CallAIParams): Promise<string> {
    const ollamaUrl = process.env.OLLAMA_API_URL || 'http://localhost:11434';
    
    console.log(`ğŸš€ ë¡œì»¬ Ollama í˜¸ì¶œ: ${ollamaUrl}`);
    
    const response = await fetch(`${ollamaUrl}/api/generate`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'phi3:mini',
        prompt: params.prompt || '',
        stream: false,
        options: {
          temperature: params.temperature || 0.7,
          num_predict: params.maxTokens || 2048,
          top_k: 40,
          top_p: 0.95,
          repeat_penalty: 1.1
        }
      }),
      signal: AbortSignal.timeout(300000) // 5ë¶„ íƒ€ì„ì•„ì›ƒ
    });

    if (!response.ok) {
      throw new Error(`ë¡œì»¬ Ollama ì˜¤ë¥˜: ${response.status}`);
    }

    const result = await response.json();
    return result.response || '';
  }

  /**
   * ëŒ€ì²´ AI ì„œë¹„ìŠ¤ í˜¸ì¶œ (ë¡œì»¬ Ollama ì‚¬ìš© ë¶ˆê°€ ì‹œ)
   */
  private async callFallbackAI(params: CallAIParams): Promise<string> {
    console.log('ğŸ”„ ëŒ€ì²´ AI ì„œë¹„ìŠ¤ í˜¸ì¶œ ì¤‘...');
    
    // ê°„ë‹¨í•œ ëŒ€ì²´ ì‘ë‹µ ìƒì„± (ì‹¤ì œë¡œëŠ” ì™¸ë¶€ AI API ì‚¬ìš©)
    const fallbackResponse = this.generateFallbackResponse(params.prompt || '');
    
    return fallbackResponse;
  }

  /**
   * ëŒ€ì²´ ì‘ë‹µ ìƒì„± (ë¡œì»¬ Ollama ì‚¬ìš© ë¶ˆê°€ ì‹œ)
   */
  private generateFallbackResponse(prompt: string): string {
    console.log('âš ï¸ ë¡œì»¬ Ollama ì„œë²„ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.');
    
    // í˜¸ìŠ¤íŠ¸ ìƒíƒœ í™•ì¸
    const hostStatus = hostStatusMonitor.getUserFriendlyStatus();
    const downtimeInfo = hostStatus.downtimeDuration ? ` (ì¤‘ë‹¨ ì‹œê°„: ${hostStatus.downtimeDuration})` : '';
    
    if (prompt.includes('AI ì—­ëŸ‰ì§„ë‹¨') || prompt.includes('ì§„ë‹¨ ë³´ê³ ì„œ')) {
      return `ì•ˆë…•í•˜ì„¸ìš”! AI ì—­ëŸ‰ì§„ë‹¨ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

í˜„ì¬ í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

ğŸ”§ **ì„œë¹„ìŠ¤ ìƒíƒœ**
- í˜¸ìŠ¤íŠ¸ ì»´í“¨í„°: ì—°ê²° ë¶ˆê°€${downtimeInfo}
- ë¡œì»¬ Ollama ì„œë²„: ì—°ê²° ë¶ˆê°€
- AI ëª¨ë¸: phi3:mini (ì˜¤í”„ë¼ì¸)
- ëŒ€ì²´ ëª¨ë“œ: í™œì„±í™”

ğŸ“‹ **AI ì—­ëŸ‰ì§„ë‹¨ ì•ˆë‚´**
1. **ì‚¬ì—… ê¸°ë°˜**: AI ë„ì…ì„ ìœ„í•œ ê¸°ë³¸ ì¸í”„ë¼
2. **í˜„ì¬ AI í™œìš©**: ê¸°ì¡´ AI ë„êµ¬ ì‚¬ìš© í˜„í™©
3. **ì¡°ì§ ì¤€ë¹„ë„**: AI ë„ì…ì„ ìœ„í•œ ì¡°ì§ ì—­ëŸ‰
4. **ê¸°ìˆ  ì¸í”„ë¼**: AI ê¸°ìˆ  ì§€ì› í™˜ê²½
5. **ì „ëµ ëª…í™•ì„±**: AI ì „ëµ ìˆ˜ë¦½ ë° ì‹¤í–‰ ê³„íš
6. **ì‹¤í–‰ ì—­ëŸ‰**: AI í”„ë¡œì íŠ¸ ì‹¤í–‰ ëŠ¥ë ¥

ğŸ’¡ **ê¶Œì¥ì‚¬í•­**
- í˜¸ìŠ¤íŠ¸ ì»´í“¨í„°ì˜ ì „ì›ì„ í™•ì¸í•´ì£¼ì„¸ìš”
- Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœë¥¼ ì ê²€í•´ì£¼ì„¸ìš”

${hostStatus.showEmailRequest ? `
ğŸš¨ **ì„œë²„ ì‚¬ìš© ì‹ ì²­**
í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ê°€ ì¥ì‹œê°„ ì¤‘ë‹¨ëœ ê²½ìš°, ì„œë²„ ê´€ë¦¬ìì—ê²Œ ì‚¬ìš© ì‹ ì²­ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì´ë©”ì¼: hongik423@gmail.com
- ì‹ ì²­ í˜ì´ì§€: /server-downtime
` : ''}

ë” ì •í™•í•œ ì§„ë‹¨ì„ ìœ„í•´ì„œëŠ” í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.`;
    }
    
    if (prompt.includes('ì±—ë´‡') || prompt.includes('ìƒë‹´')) {
      return `ì•ˆë…•í•˜ì„¸ìš”! AI ì±—ë´‡ ìƒë‹´ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

í˜„ì¬ í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤.

ğŸ¤– **AI ì±—ë´‡ ìƒë‹´ ì•ˆë‚´**
- ì„œë¹„ìŠ¤: AI ì—­ëŸ‰ì§„ë‹¨ ë° ìƒë‹´
- ëª¨ë¸: phi3:mini (ì˜¤í”„ë¼ì¸)
- ìƒíƒœ: ëŒ€ì²´ ëª¨ë“œ${downtimeInfo ? ` (ì¤‘ë‹¨ ì‹œê°„: ${downtimeInfo})` : ''}

ğŸ’¬ **ìƒë‹´ ê°€ëŠ¥ ë¶„ì•¼**
1. AI ë„ì… ì „ëµ ìˆ˜ë¦½
2. AI ì—­ëŸ‰ì§„ë‹¨ ë°©ë²•ë¡ 
3. AI í”„ë¡œì íŠ¸ ì‹¤í–‰ ê°€ì´ë“œ
4. AI êµìœ¡ ë° í›ˆë ¨ ë°©ì•ˆ
5. AI ê¸°ìˆ  ì¸í”„ë¼ êµ¬ì¶•

ğŸ”§ **ì„œë¹„ìŠ¤ ë³µêµ¬ ë°©ë²•**
- í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì „ì› í™•ì¸
- Ollama ì„œë²„ ì‹¤í–‰ ìƒíƒœ ì ê²€
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸

${hostStatus.showEmailRequest ? `
ğŸš¨ **ì„œë²„ ì‚¬ìš© ì‹ ì²­**
í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ê°€ ì¥ì‹œê°„ ì¤‘ë‹¨ëœ ê²½ìš°, ì„œë²„ ê´€ë¦¬ìì—ê²Œ ì‚¬ìš© ì‹ ì²­ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì´ë©”ì¼: hongik423@gmail.com
- ì‹ ì²­ í˜ì´ì§€: /server-downtime
` : ''}

ë” ì •í™•í•œ AI ìƒë‹´ì„ ìœ„í•´ì„œëŠ” í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.`;
    }
    
    return `ì•ˆë…•í•˜ì„¸ìš”! AI ìƒë‹´ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

í˜„ì¬ í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ê¸°ë³¸ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

ğŸ”§ **ì„œë¹„ìŠ¤ ìƒíƒœ**
- í˜¸ìŠ¤íŠ¸ ì»´í“¨í„°: ì—°ê²° ë¶ˆê°€${downtimeInfo}
- ë¡œì»¬ AI ì„œë²„: ì—°ê²° ë¶ˆê°€
- ëŒ€ì²´ ëª¨ë“œ: í™œì„±í™”

${hostStatus.showEmailRequest ? `
ğŸš¨ **ì„œë²„ ì‚¬ìš© ì‹ ì²­**
í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ê°€ ì¥ì‹œê°„ ì¤‘ë‹¨ëœ ê²½ìš°, ì„œë²„ ê´€ë¦¬ìì—ê²Œ ì‚¬ìš© ì‹ ì²­ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì´ë©”ì¼: hongik423@gmail.com
- ì‹ ì²­ í˜ì´ì§€: /server-downtime
` : ''}

ë” ì •í™•í•œ AI ì‘ë‹µì„ ìœ„í•´ì„œëŠ” í˜¸ìŠ¤íŠ¸ ì»´í“¨í„° ì„œë²„ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.

í˜¸ìŠ¤íŠ¸ ì»´í“¨í„°ì˜ ì „ì›ê³¼ Ollama ì„œë²„ ì‹¤í–‰ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.`;
  }

  /**
   * í•˜ì´ë¸Œë¦¬ë“œ AI í˜¸ì¶œ (ë¡œì»¬ ìš°ì„ , ëŒ€ì²´ ì„œë¹„ìŠ¤ ë°±ì—…)
   */
  async callAI(params: CallAIParams): Promise<HybridAIResponse> {
    const startTime = Date.now();
    
    try {
      // ë¡œì»¬ Ollama ì„œë²„ ìƒíƒœ í™•ì¸
      const ollamaStatus = await this.checkOllamaStatus();
      
      if (ollamaStatus.isRunning && ollamaStatus.modelAvailable) {
        // ë¡œì»¬ Ollama ì‚¬ìš© ê°€ëŠ¥ - ë¡œì»¬ í˜¸ì¶œ
        console.log('ğŸ¯ ë¡œì»¬ Ollama ì„œë²„ ì‚¬ìš©: phi3:mini');
        
        const response = await this.callLocalOllama(params);
        const processingTime = Date.now() - startTime;
        
        return {
          response,
          source: 'local',
          processingTime,
          modelUsed: 'phi3:mini (ë¡œì»¬)',
          metadata: {
            localOllamaAvailable: true
          }
        };
        
      } else {
        // ë¡œì»¬ Ollama ì‚¬ìš© ë¶ˆê°€ - ëŒ€ì²´ ì„œë¹„ìŠ¤ ì‚¬ìš©
        console.log('âš ï¸ ë¡œì»¬ Ollama ì‚¬ìš© ë¶ˆê°€, ëŒ€ì²´ ì„œë¹„ìŠ¤ ì‚¬ìš©');
        
        const response = await this.callFallbackAI(params);
        const processingTime = Date.now() - startTime;
        
        return {
          response,
          source: 'fallback',
          processingTime,
          modelUsed: 'ê¸°ë³¸ ì‘ë‹µ (ëŒ€ì²´)',
          metadata: {
            localOllamaAvailable: false,
            fallbackReason: ollamaStatus.error || 'Ollama ì„œë²„ ì—°ê²° ë¶ˆê°€'
          }
        };
      }
      
    } catch (error) {
      console.error('âŒ í•˜ì´ë¸Œë¦¬ë“œ AI í˜¸ì¶œ ì‹¤íŒ¨:', error);
      
      const processingTime = Date.now() - startTime;
      const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
      
      return {
        response: `ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nì˜¤ë¥˜: ${errorMessage}\n\ní˜¸ìŠ¤íŠ¸ ì»´í“¨í„°ì˜ ì „ì›ê³¼ Ollama ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.`,
        source: 'fallback',
        processingTime,
        modelUsed: 'ì˜¤ë¥˜ ì‘ë‹µ',
        metadata: {
          localOllamaAvailable: false,
          fallbackReason: errorMessage
        }
      };
    }
  }

  /**
   * í˜„ì¬ AI ì„œë¹„ìŠ¤ ìƒíƒœ ë°˜í™˜
   */
  async getServiceStatus(): Promise<ServiceStatus> {
    const status = await this.checkOllamaStatus();
    
    return {
      localOllamaAvailable: status.isRunning && status.modelAvailable,
      modelName: status.modelName,
      lastChecked: status.lastChecked,
      responseTime: status.responseTime,
      error: status.error
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë‚´ë³´ë‚´ê¸°
export const hybridAIProvider = HybridAIProvider.getInstance();
